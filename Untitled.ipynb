{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a4b7af7",
   "metadata": {},
   "source": [
    "## 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343ae7f2",
   "metadata": {},
   "source": [
    "In the modern era we are blessed with an enormous quantity of information. Everything can be found online, probably every bit of human knowledge is available with a few clicks, and most of it is completely free.\n",
    "The downside of the connected world is probably the fact that there's no filter, everyone with a smartphone can post information online, and the more this information is repeated and liked (or disliked) in general the more it will be potent and influential (and also profitable), regardless of its veridicity.\n",
    "With the term fake news we identify any false or midleading information presented as news [1], and we have seen them interfere with elections, COVID-19 vaccination programs, and ruin the reputation of many people in the last years.\n",
    "The problem of automatically detect fake news it's not an easy one to solve, in this paper we will briefly look at the state of the art and try to add novelty to a particular approach."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc9f7e9",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "[1] https://en.wikipedia.org/wiki/Fake_news\n",
    "\n",
    "[2] Y. Chen, N. J. Conroy, and V. L. Rubin, “News in an online world: The need for an automatic crap detector,” Proceedings of the Association for Information Science and Technology, vol. 52, no. 1, pp. 1–4, 2015.\n",
    "\n",
    "[3] Parikh, S.B. & Atrey, P.K. 2018, \"Media-Rich Fake News Detection: A Survey\", IEEE, , pp. 436.\n",
    "\n",
    "[4] W. Y. Wang, “” liar, liar pants on fire”: A new benchmark dataset for fake news detection,” arXiv preprint\n",
    "arXiv:1705.00648, 2017\n",
    "\n",
    "[5] Ahmed H, Traore I, Saad S. “Detecting opinion spams and fake news using text classification”, Journal of Security and Privacy, Volume 1, Issue 1, Wiley, January/February 2018.\n",
    "\n",
    "[6] Ahmed H, Traore I, Saad S. (2017) “Detection of Online Fake News Using N-Gram Analysis and Machine Learning Techniques. In: Traore I., Woungang I., Awad A. (eds) Intelligent, Secure, and Dependable Systems in Distributed and Cloud Environments. ISDDC 2017. Lecture Notes in Computer Science, vol 10618. Springer, Cham (pp. 127-138).\n",
    "\n",
    "[7] https://www.kaggle.com/clmentbisaillon/fake-and-real-news-dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c2107b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d509d1d0",
   "metadata": {},
   "source": [
    "### 1.1 Domain-specific Area\n",
    "\n",
    "According to [2] the problem of automatically detect fake news is not easy to solve because of two factors: \n",
    "\n",
    "1. The Fake news content can be images or video or a podcast, very easy to fake but a lot more complex to analyze and preprocess than normal text.\n",
    "2. There is no way in knowing where people take their information from. The web is full of platforms that provide news and governance is basically non-existant\n",
    "\n",
    "But nonetheless the ML community has developed a series of solutions to tackle the problem with promising results (at least in the text-based news domain). In the survey by Shivam B. Parikh and Pradeep K. Atrey [3] the approcheas are divided in six methodology groups: \n",
    "\n",
    "1. Linguistic Features based Methods, based on the extraction and classification of  linguistic features from fake news, usually using a tdfidf representation of the text.\n",
    "2. Deception Modeling based Methods, based on the extraction of the relations between text units on a story as an hierarchical tree.\n",
    "3. Clustering based Methods, based on agglomerative clustering alghoritms (such as KNN) trained on a large number of data sets.\n",
    "4. Predictive Modeling based Methods, based on logistic regression and positive or negative coefficients to point out the deception probability of a given text.\n",
    "5. Content Cues based Methods, based on the assumption that the fake news is created solely to engage the readers, unlike a real news,  and some form of linguistic pattern are an indicator of this purpose\n",
    "6. Non-Text Cues based Methods, focuses on the analsis of two non-text components of a news: images and user behavior.\n",
    "\n",
    "In this work the focus will be on methodologies of class 1, the text will be processed and stored as a tf-idf matrix and different models will be evaluated against a baseline.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4002196c",
   "metadata": {},
   "source": [
    "### 1.2 Description of the selected dataset\n",
    "\n",
    "The datasets used for this analysis are three: \n",
    "\n",
    "The <b>LIAR</b> dataset presented in [4] and available to the public. It is composed of 12,8 K human labeled short statements from politifact.com labeled with truthfulness ratings: pants-fire, false, barely-true, half-true, mostly-true, and true. The dataset is well balanced and since the analysis will be a binary one (fake news yes/no), to mantain balance we apply the following mapping: \n",
    "\n",
    " - pants-fire: fake news\n",
    " \n",
    " - false: fake news\n",
    "  \n",
    " - barely-true: fake news\n",
    " \n",
    " - half-true: true\n",
    " \n",
    " - mostly-trye: true\n",
    " \n",
    " - true: true\n",
    " \n",
    "\n",
    "The LIAR dataset is downloaded as three tsv files divided in train, test and validation set. It is composed of the following columns: \n",
    "\n",
    "1. ID - Text\n",
    "\n",
    "2. Label - Text\n",
    "\n",
    "3. Statement - Text\n",
    "\n",
    "4. Subject - Text\n",
    "\n",
    "5. Speaker - Text\n",
    "\n",
    "6. Speaker Job Title - Text\n",
    "\n",
    "7. State - Text\n",
    "\n",
    "8. Party affiliation - Text - [democrat, republican]\n",
    "\n",
    "9. Barely true count - Integer\n",
    "\n",
    "10. Half true counts - Integer\n",
    "\n",
    "11. Mostly true counts - Integer\n",
    "\n",
    "12. Pants on fire counts - Integer\n",
    "\n",
    "13. Venue / location of the statement - Text\n",
    "\n",
    "\n",
    "The second dataset is the <b>ISOT Fake News Dataset</b>, introduced by Ahmed H, Traore I and Saad S. in [5], [6] and available on Kaggle [7]. It is composed of 21417 true news articles and 23481 fake news. The truthful articles were obtained by crawling articles from Reuters.com, and the fake news from different sources, mostly unreliable websites flagged by politifact and Wikipedia.\n",
    "\n",
    "The ISOT dataset is downloaded as two csv files, true.csv and fake.csv. It is composed of the following columns: \n",
    "\n",
    "1. Title - Text\n",
    "\n",
    "2. Text - Text\n",
    "\n",
    "3. Subject - Text\n",
    "\n",
    "4. Date - Date\n",
    "\n",
    "\n",
    "Both the described datasets will be reduced to the same format for this analysis: \n",
    "\n",
    "1. Article - Text\n",
    "\n",
    "2. isFake - Boolean\n",
    "\n",
    "\n",
    "From the LIAR dataset we'll sample 3K random rows from the train file and from the ISOT dataset we'll sample 1,5K random rows from the true file and 1,5k rows from the fake file.\n",
    "\n",
    "\n",
    "The third dataset used is a validation dataset and is the concatenation of the previous two datasets. It will have the standard format and it'll be composed of 6K rows.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8160dcdd",
   "metadata": {},
   "source": [
    "### 1.3 Objectives\n",
    "\n",
    "The objectives of this project are mainly two: \n",
    "\n",
    "1. Explore different ensemble methodologies with a set of classificators that will be the baseline agaist wich the ensembles will be evaluated. Study the differences between those methodologies and find if there's one best suited to the task of finding fake news. The ensemble techniques that will be used are: \n",
    "\n",
    "<b>Hard Blending Ensemble</b>, a form of Stacking Generalization without the k-fold cross validation.We use the predictions of the base models to create a \"meta-model\" that will be then used as training for a \"blending model\" (in our case Logistic Regressor) that will do the actual predictions.\n",
    "\n",
    "<b>Soft Blending Ensemble</b>, like above, but with the difference that instead of using the predictions of the base models as meta-model we will use the probabilities given by the models as training for the blender\n",
    "\n",
    "<b>Soft Weighted Voting Ensemble</b>, a form of Voting Ensemble in which the predictions of the base models will result in a prediction based on the majority vote, with a weight given by the accuracy of the single base model on a validation set\n",
    "\n",
    "\n",
    "2. Create an ensemble that can outperform any of the  single \"weak learner\" composing the ensemble classificator."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dda711f",
   "metadata": {},
   "source": [
    "### 1.4 Evaluation Methodology"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9318d0",
   "metadata": {},
   "source": [
    "2. Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48515c2d",
   "metadata": {},
   "source": [
    "2.1 Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "43d7acea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/mmenna/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import string\n",
    "import random\n",
    "import numpy as np\n",
    "from numpy import hstack\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk import ngrams\n",
    "from functools import reduce\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.extmath import softmax\n",
    "\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import tree\n",
    "\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "\n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec98e831",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_processing(text, n = 1):\n",
    "    \"\"\"\n",
    "    Takes in a string of text, then performs the following:\n",
    "    1. Convert text to lower case and remove all punctuation\n",
    "    2. Optionally apply stemming\n",
    "    3. Apply Ngram Tokenisation\n",
    "    4. Returns the tokenised text as a list \n",
    "    \"\"\"\n",
    "    \n",
    "    stemmer = SnowballStemmer(\"english\")\n",
    "    stop = stopwords.words('english')\n",
    "    #write steps here\n",
    "    # lower function\n",
    "    t_1 = lambda x : x.lower()\n",
    "    # Remove punctuation function\n",
    "    t_2 = lambda x : x.translate(str.maketrans('', '', string.punctuation))\n",
    "    # Remove stopwords\n",
    "    t_3 = lambda x : \" \".join([w for w in x.split() if w not in stop])\n",
    "    # Snowball stemming\n",
    "    t_4 = lambda x : \" \".join([stemmer.stem(w) for w in x.split()])\n",
    "    # Ngrams with n number of grams\n",
    "    t_5 = lambda x : [\" \".join(ng) for ng in list(ngrams(x.split(), n))]\n",
    "    \n",
    "    \n",
    "    #List of transformation functions\n",
    "    t = [t_1, t_2, t_3, t_4, t_5]\n",
    "    \n",
    "    #Apply transformations\n",
    "    tokenised = reduce(lambda r, f: f(r), t, text)\n",
    "    \n",
    "    return tokenised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d501f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_1 = sum(1 for line in open('True.csv')) - 1\n",
    "n_2 = sum(1 for line in open('Fake.csv')) - 1\n",
    "s = 1500\n",
    "skip_1 = sorted(random.sample(range(1,n_1+1),n_1-s)) \n",
    "skip_2 = sorted(random.sample(range(1,n_2+1),n_2-s))\n",
    "\n",
    "\n",
    "raw_data_true = pd.read_csv('True.csv', skiprows=skip_1)\n",
    "raw_data_fake = pd.read_csv('Fake.csv', skiprows=skip_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7dd86a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_true['isFake'] = 0\n",
    "raw_data_fake['isFake'] = 1\n",
    "raw_data = raw_data_true.append(raw_data_fake)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09af5775",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_t1 = pd.DataFrame()\n",
    "data_t1['article'] = raw_data['title'] + ' ' + raw_data['text']\n",
    "data_t1['isFake'] = raw_data['isFake']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1893ab8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [trump, say, russia, probe, fair, timelin, unc...\n",
       "1       [mcconnel, happier, trump, tweet, tax, victori...\n",
       "2       [republican, aim, ride, economi, elect, victor...\n",
       "3       [congress, vote, avert, shutdown, send, trump,...\n",
       "4       [us, hous, approv, 81, billion, disast, aid, w...\n",
       "                              ...                        \n",
       "1493    [peac, prize, presid, obama, approv, 200, bill...\n",
       "1494    [reopen, kurt, cobain, case, poll, 21st, centu...\n",
       "1495    [plastic, persona, behind, scene, ted, cruz, m...\n",
       "1496    [activist, this, make, impact, 21st, centuri, ...\n",
       "1497    [trial, youtub, mainstream, media, use, second...\n",
       "Name: article, Length: 2998, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag = data_t1['article'].apply(text_processing, n=1)\n",
    "bag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28fb4b23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count Vectorizing...\n",
      "Transforming to tfidf matrix...\n"
     ]
    }
   ],
   "source": [
    "identity = lambda x : x\n",
    "corpus = bag.values\n",
    "print('Count Vectorizing...')\n",
    "vectorizer = CountVectorizer(tokenizer = identity, preprocessor = identity)\n",
    "count_vector = vectorizer.fit_transform(corpus).toarray()\n",
    "print('Transforming to tfidf matrix...')\n",
    "tfidfTransformer = TfidfTransformer()\n",
    "text_tfidf = tfidfTransformer.fit_transform(count_vector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff024d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(text_tfidf.toarray())\n",
    "y = data_t1['isFake']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "8bfe6774",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = sum(1 for line in open('liar_dataset/train.tsv')) - 1\n",
    "s = 3000\n",
    "skip = sorted(random.sample(range(1,n-1),n-s)) \n",
    "\n",
    "l_raw_data = pd.read_csv('liar_dataset/train.tsv', sep='\\t', names= ['ID','Label','Statement', 'Subject', 'Speaker', 'Speaker Job', 'State', 'Party Aff', 'Credit', 'True', 'Half true', 'Mostly true', 'Pants on fire', 'Context'], skiprows=skip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "bd47d837",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>isFake</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Says the Annies List political group supports ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Chicago Bears have had more starting quart...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Since 2000, nearly 12 million Americans have s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Says Mitt Romney wants to get rid of Planned P...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>We have a federal government that thinks they ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2991</th>\n",
       "      <td>As a result of Obamacare, California seniors f...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2992</th>\n",
       "      <td>For the first time since the Korean War, total...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2993</th>\n",
       "      <td>The proudest accomplishment (of my tenure) was...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2994</th>\n",
       "      <td>Mayor Fung wants to punish our childrens educa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>Under the ruling of the Supreme Court, any lob...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2996 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                article  isFake\n",
       "0     Says the Annies List political group supports ...       1\n",
       "1     The Chicago Bears have had more starting quart...       0\n",
       "2     Since 2000, nearly 12 million Americans have s...       0\n",
       "3     Says Mitt Romney wants to get rid of Planned P...       1\n",
       "4     We have a federal government that thinks they ...       0\n",
       "...                                                 ...     ...\n",
       "2991  As a result of Obamacare, California seniors f...       1\n",
       "2992  For the first time since the Korean War, total...       0\n",
       "2993  The proudest accomplishment (of my tenure) was...       0\n",
       "2994  Mayor Fung wants to punish our childrens educa...       1\n",
       "2995  Under the ruling of the Supreme Court, any lob...       0\n",
       "\n",
       "[2996 rows x 2 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "liar_mapper = {\n",
    "    'false': 1,\n",
    "    'half-true': 0,\n",
    "    'mostly-true': 0,\n",
    "    'true': 0,\n",
    "    'barely-true': 1,\n",
    "    'pants-fire': 1\n",
    "}\n",
    "reduce_fake = lambda x : liar_mapper[x]\n",
    "l_data_t1 = pd.DataFrame()\n",
    "l_data_t1['article'] = l_raw_data['Statement']\n",
    "l_data_t1['isFake'] = l_raw_data['Label'].apply(reduce_fake)\n",
    "\n",
    "l_data_t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "4b5a625f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [say, anni, list, polit, group, support, third...\n",
       "1       [chicago, bear, start, quarterback, last, 10, ...\n",
       "2       [sinc, 2000, near, 12, million, american, slip...\n",
       "3       [say, mitt, romney, want, get, rid, plan, pare...\n",
       "4       [feder, govern, think, author, regul, toilet, ...\n",
       "                              ...                        \n",
       "2991    [result, obamacar, california, senior, face, b...\n",
       "2992    [first, time, sinc, korean, war, total, feder,...\n",
       "2993    [proudest, accomplish, tenur, leav, state, 12,...\n",
       "2994    [mayor, fung, want, punish, children, educ, re...\n",
       "2995    [rule, suprem, court, lobbyist, could, go, leg...\n",
       "Name: article, Length: 2996, dtype: object"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag = l_data_t1['article'].apply(text_processing, n=1)\n",
    "bag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "763bfebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count Vectorizing...\n",
      "Transforming to tfidf matrix...\n"
     ]
    }
   ],
   "source": [
    "corpus = bag.values\n",
    "print('Count Vectorizing...')\n",
    "vectorizer = CountVectorizer(tokenizer = identity, preprocessor = identity)\n",
    "count_vector = vectorizer.fit_transform(corpus).toarray()\n",
    "print('Transforming to tfidf matrix...')\n",
    "tfidfTransformer = TfidfTransformer()\n",
    "text_tfidf = tfidfTransformer.fit_transform(count_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "7fb5446d",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_X = pd.DataFrame(text_tfidf.toarray())\n",
    "l_y = l_data_t1['isFake']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "88e0d2b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>isFake</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Trump says Russia probe will be fair, but time...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>McConnell happier with Trump tweets after tax ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>As Republicans aim to ride economy to election...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Congress votes to avert shutdown, sends Trump ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>U.S. House approves $81 billion for disaster a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2991</th>\n",
       "      <td>As a result of Obamacare, California seniors f...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2992</th>\n",
       "      <td>For the first time since the Korean War, total...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2993</th>\n",
       "      <td>The proudest accomplishment (of my tenure) was...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2994</th>\n",
       "      <td>Mayor Fung wants to punish our childrens educa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>Under the ruling of the Supreme Court, any lob...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5994 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                article  isFake\n",
       "0     Trump says Russia probe will be fair, but time...       0\n",
       "1     McConnell happier with Trump tweets after tax ...       0\n",
       "2     As Republicans aim to ride economy to election...       0\n",
       "3     Congress votes to avert shutdown, sends Trump ...       0\n",
       "4     U.S. House approves $81 billion for disaster a...       0\n",
       "...                                                 ...     ...\n",
       "2991  As a result of Obamacare, California seniors f...       1\n",
       "2992  For the first time since the Korean War, total...       0\n",
       "2993  The proudest accomplishment (of my tenure) was...       0\n",
       "2994  Mayor Fung wants to punish our childrens educa...       1\n",
       "2995  Under the ruling of the Supreme Court, any lob...       0\n",
       "\n",
       "[5994 rows x 2 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_data_t1 = data_t1.append(l_data_t1)\n",
    "t_data_t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "e337ab89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count Vectorizing...\n",
      "Transforming to tfidf matrix...\n"
     ]
    }
   ],
   "source": [
    "t_data_t1 = data_t1.append(l_data_t1)\n",
    "bag = t_data_t1['article'].apply(text_processing, n=1)\n",
    "corpus = bag.values\n",
    "print('Count Vectorizing...')\n",
    "vectorizer = CountVectorizer(tokenizer = identity, preprocessor = identity)\n",
    "count_vector = vectorizer.fit_transform(corpus).toarray()\n",
    "print('Transforming to tfidf matrix...')\n",
    "tfidfTransformer = TfidfTransformer()\n",
    "text_tfidf = tfidfTransformer.fit_transform(count_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "4d4a993f",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_X = pd.DataFrame(text_tfidf.toarray())\n",
    "t_y = t_data_t1['isFake']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcceb5cf",
   "metadata": {},
   "source": [
    "2.2 Baseline performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "b19bfa26",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RidgeClassifierWithProba(RidgeClassifier):\n",
    "    def predict_proba(self, X):\n",
    "        d = self.decision_function(X)\n",
    "        d_2d = np.c_[-d, d]\n",
    "        \n",
    "        return softmax(d_2d)\n",
    "    \n",
    "models= [tree.DecisionTreeClassifier(), \n",
    "         LogisticRegression(random_state=42), \n",
    "         SGDClassifier(max_iter=1000, tol=1e-3, loss='modified_huber'),\n",
    "         RidgeClassifierWithProba(),\n",
    "         MultinomialNB()\n",
    "        ]\n",
    "model_names = [\n",
    "    \"Decision Tree\",\n",
    "    \"Logistic Regression\",\n",
    "    \"Stocasthic Gradient Descent\",\n",
    "    \"Ridge\",\n",
    "    \"Naive Bayes\"\n",
    "]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "l_X_train, l_X_test, l_y_train, l_y_test = train_test_split(l_X, l_y, test_size=0.2)\n",
    "t_X_train, t_X_test, t_y_train, t_y_test = train_test_split(t_X, t_y, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decc21d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "c84992f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting model  Decision Tree for Fake News dataset...\n",
      "Fitting model  Decision Tree for Liar dataset...\n",
      "Fitting model  Decision Tree for Total dataset...\n",
      "Fitting model  Logistic Regression for Fake News dataset...\n",
      "Fitting model  Logistic Regression for Liar dataset...\n",
      "Fitting model  Logistic Regression for Total dataset...\n",
      "Fitting model  Stocasthic Gradient Descent for Fake News dataset...\n",
      "Fitting model  Stocasthic Gradient Descent for Liar dataset...\n",
      "Fitting model  Stocasthic Gradient Descent for Total dataset...\n",
      "Fitting model  Ridge for Fake News dataset...\n",
      "Fitting model  Ridge for Liar dataset...\n",
      "Fitting model  Ridge for Total dataset...\n",
      "Fitting model  Naive Bayes for Fake News dataset...\n",
      "Fitting model  Naive Bayes for Liar dataset...\n",
      "Fitting model  Naive Bayes for Total dataset...\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "l_scores = []\n",
    "t_scores = []\n",
    "for i,model in enumerate(models):\n",
    "    print('Fitting model ', model_names[i], 'for Fake News dataset...')\n",
    "    model.fit(X_train, y_train)\n",
    "    yhat = model.predict(X_test)\n",
    "    scores.append([\n",
    "        model_names[i],\n",
    "        yhat,\n",
    "        roc_auc_score(y_test, yhat),\n",
    "        f1_score(y_test, yhat),\n",
    "        precision_score(y_test, yhat),\n",
    "        recall_score(y_test, yhat),\n",
    "        accuracy_score(y_test, yhat)\n",
    "    ])\n",
    "    print('Fitting model ', model_names[i], 'for Liar dataset...')\n",
    "    model.fit(l_X_train, l_y_train)\n",
    "    yhat = model.predict(l_X_test)\n",
    "    l_scores.append([\n",
    "        model_names[i],\n",
    "        yhat,\n",
    "        roc_auc_score(l_y_test, yhat),\n",
    "        f1_score(l_y_test, yhat),\n",
    "        precision_score(l_y_test, yhat),\n",
    "        recall_score(l_y_test, yhat),\n",
    "        accuracy_score(l_y_test, yhat)\n",
    "    ])\n",
    "    print('Fitting model ', model_names[i], 'for Total dataset...')\n",
    "    model.fit(t_X_train, t_y_train)\n",
    "    yhat = model.predict(t_X_test)\n",
    "    t_scores.append([\n",
    "        model_names[i],\n",
    "        yhat,\n",
    "        roc_auc_score(t_y_test, yhat),\n",
    "        f1_score(t_y_test, yhat),\n",
    "        precision_score(t_y_test, yhat),\n",
    "        recall_score(t_y_test, yhat),\n",
    "        accuracy_score(t_y_test, yhat)\n",
    "    ])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "cfa1632e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df = pd.DataFrame(scores, columns= ['Model', 'Predictions', 'ROC AUC', 'F1-Score', 'Precision', 'Recall', 'Accuracy'])\n",
    "l_scores_df = pd.DataFrame(l_scores, columns= ['Model', 'Predictions', 'ROC AUC', 'F1-Score', 'Precision', 'Recall', 'Accuracy'])\n",
    "t_scores_df = pd.DataFrame(t_scores, columns= ['Model', 'Predictions', 'ROC AUC', 'F1-Score', 'Precision', 'Recall', 'Accuracy'])\n",
    "\n",
    "baseline_scores = scores\n",
    "l_baseline_scores = l_scores\n",
    "t_baseline_scores = t_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "efc3e73e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Predictions</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, ...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, ...</td>\n",
       "      <td>0.976621</td>\n",
       "      <td>0.976351</td>\n",
       "      <td>0.982993</td>\n",
       "      <td>0.969799</td>\n",
       "      <td>0.976667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stocasthic Gradient Descent</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, ...</td>\n",
       "      <td>0.981677</td>\n",
       "      <td>0.981575</td>\n",
       "      <td>0.979933</td>\n",
       "      <td>0.983221</td>\n",
       "      <td>0.981667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, ...</td>\n",
       "      <td>0.988299</td>\n",
       "      <td>0.988196</td>\n",
       "      <td>0.993220</td>\n",
       "      <td>0.983221</td>\n",
       "      <td>0.988333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, ...</td>\n",
       "      <td>0.954831</td>\n",
       "      <td>0.953528</td>\n",
       "      <td>0.978799</td>\n",
       "      <td>0.929530</td>\n",
       "      <td>0.955000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Model  \\\n",
       "0                Decision Tree   \n",
       "1          Logistic Regression   \n",
       "2  Stocasthic Gradient Descent   \n",
       "3                        Ridge   \n",
       "4                  Naive Bayes   \n",
       "\n",
       "                                         Predictions   ROC AUC  F1-Score  \\\n",
       "0  [0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, ...  1.000000  1.000000   \n",
       "1  [0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, ...  0.976621  0.976351   \n",
       "2  [0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, ...  0.981677  0.981575   \n",
       "3  [0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, ...  0.988299  0.988196   \n",
       "4  [0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, ...  0.954831  0.953528   \n",
       "\n",
       "   Precision    Recall  Accuracy  \n",
       "0   1.000000  1.000000  1.000000  \n",
       "1   0.982993  0.969799  0.976667  \n",
       "2   0.979933  0.983221  0.981667  \n",
       "3   0.993220  0.983221  0.988333  \n",
       "4   0.978799  0.929530  0.955000  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "11987146",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Predictions</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>[1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, ...</td>\n",
       "      <td>0.552486</td>\n",
       "      <td>0.537005</td>\n",
       "      <td>0.513158</td>\n",
       "      <td>0.563177</td>\n",
       "      <td>0.551667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>[0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...</td>\n",
       "      <td>0.578579</td>\n",
       "      <td>0.491736</td>\n",
       "      <td>0.574879</td>\n",
       "      <td>0.429603</td>\n",
       "      <td>0.590000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stocasthic Gradient Descent</td>\n",
       "      <td>[1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, ...</td>\n",
       "      <td>0.554548</td>\n",
       "      <td>0.541096</td>\n",
       "      <td>0.514658</td>\n",
       "      <td>0.570397</td>\n",
       "      <td>0.553333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>[0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, ...</td>\n",
       "      <td>0.564630</td>\n",
       "      <td>0.515038</td>\n",
       "      <td>0.537255</td>\n",
       "      <td>0.494585</td>\n",
       "      <td>0.570000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0.573711</td>\n",
       "      <td>0.402948</td>\n",
       "      <td>0.630769</td>\n",
       "      <td>0.296029</td>\n",
       "      <td>0.595000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Model  \\\n",
       "0                Decision Tree   \n",
       "1          Logistic Regression   \n",
       "2  Stocasthic Gradient Descent   \n",
       "3                        Ridge   \n",
       "4                  Naive Bayes   \n",
       "\n",
       "                                         Predictions   ROC AUC  F1-Score  \\\n",
       "0  [1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, ...  0.552486  0.537005   \n",
       "1  [0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...  0.578579  0.491736   \n",
       "2  [1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, ...  0.554548  0.541096   \n",
       "3  [0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, ...  0.564630  0.515038   \n",
       "4  [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  0.573711  0.402948   \n",
       "\n",
       "   Precision    Recall  Accuracy  \n",
       "0   0.513158  0.563177  0.551667  \n",
       "1   0.574879  0.429603  0.590000  \n",
       "2   0.514658  0.570397  0.553333  \n",
       "3   0.537255  0.494585  0.570000  \n",
       "4   0.630769  0.296029  0.595000  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "0dc284ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Predictions</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>[0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, ...</td>\n",
       "      <td>0.772792</td>\n",
       "      <td>0.758135</td>\n",
       "      <td>0.724370</td>\n",
       "      <td>0.795203</td>\n",
       "      <td>0.770642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, ...</td>\n",
       "      <td>0.784553</td>\n",
       "      <td>0.765297</td>\n",
       "      <td>0.757685</td>\n",
       "      <td>0.773063</td>\n",
       "      <td>0.785655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stocasthic Gradient Descent</td>\n",
       "      <td>[0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>0.765551</td>\n",
       "      <td>0.753873</td>\n",
       "      <td>0.706452</td>\n",
       "      <td>0.808118</td>\n",
       "      <td>0.761468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, ...</td>\n",
       "      <td>0.778695</td>\n",
       "      <td>0.757604</td>\n",
       "      <td>0.756906</td>\n",
       "      <td>0.758303</td>\n",
       "      <td>0.780651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, ...</td>\n",
       "      <td>0.747051</td>\n",
       "      <td>0.704569</td>\n",
       "      <td>0.783296</td>\n",
       "      <td>0.640221</td>\n",
       "      <td>0.757298</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Model  \\\n",
       "0                Decision Tree   \n",
       "1          Logistic Regression   \n",
       "2  Stocasthic Gradient Descent   \n",
       "3                        Ridge   \n",
       "4                  Naive Bayes   \n",
       "\n",
       "                                         Predictions   ROC AUC  F1-Score  \\\n",
       "0  [0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, ...  0.772792  0.758135   \n",
       "1  [0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, ...  0.784553  0.765297   \n",
       "2  [0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, ...  0.765551  0.753873   \n",
       "3  [0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, ...  0.778695  0.757604   \n",
       "4  [0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, ...  0.747051  0.704569   \n",
       "\n",
       "   Precision    Recall  Accuracy  \n",
       "0   0.724370  0.795203  0.770642  \n",
       "1   0.757685  0.773063  0.785655  \n",
       "2   0.706452  0.808118  0.761468  \n",
       "3   0.756906  0.758303  0.780651  \n",
       "4   0.783296  0.640221  0.757298  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0d6dff",
   "metadata": {},
   "source": [
    "2.3 Classification Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "0d981a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the blending ensemble\n",
    "def fit_ensemble(models, X_train, X_val, y_train, y_val, hard=True):\n",
    "    # fit all models on the training set and predict on hold out set\n",
    "    meta_X = list()\n",
    "    for model in models:\n",
    "        # fit in training set\n",
    "        model.fit(X_train, y_train)\n",
    "        # predict on hold out set\n",
    "        yhat = model.predict(X_val) if hard else model.predict_proba(X_val)\n",
    "        # reshape predictions into a matrix with one column\n",
    "        if hard:\n",
    "            yhat = yhat.reshape(len(yhat), 1)\n",
    "        # store predictions as input for blending\n",
    "        meta_X.append(yhat)\n",
    "    # create 2d array from predictions, each set is an input feature\n",
    "    meta_X = hstack(meta_X)\n",
    "    # define blending model\n",
    "    blender = LogisticRegression()\n",
    "    # fit on predictions from base models\n",
    "    blender.fit(meta_X, y_val)\n",
    "    return blender\n",
    "\n",
    "# make a prediction with the blending ensemble\n",
    "def predict_ensemble(models, blender, X_test, hard=True):\n",
    "    # make predictions with base models\n",
    "    meta_X = list()\n",
    "    for model in models:\n",
    "        # predict with base model\n",
    "        yhat = model.predict(X_test) if hard else model.predict_proba(X_test)\n",
    "        # reshape predictions into a matrix with one column\n",
    "        if hard: \n",
    "            yhat = yhat.reshape(len(yhat), 1)\n",
    "        # store prediction\n",
    "        meta_X.append(yhat)\n",
    "    # create 2d array from predictions, each set is an input feature\n",
    "    meta_X = hstack(meta_X)\n",
    "    # predict\n",
    "    return blender.predict(meta_X)\n",
    "\n",
    "# evaluate each base model\n",
    "def evaluate_models(models, X_train, X_val, y_train, y_val):\n",
    "    # fit and evaluate the models\n",
    "    scores = list()\n",
    "    for model in models:\n",
    "        # fit the model\n",
    "        model.fit(X_train, y_train)\n",
    "        # evaluate the model\n",
    "        yhat = model.predict(X_val)\n",
    "        acc = accuracy_score(y_val, yhat)\n",
    "        # store the performance\n",
    "        scores.append(acc)\n",
    "    # report model performance\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "29742ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset into train and test sets\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(l_X, l_y, test_size=0.5, random_state=1)\n",
    "# split training set into train and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=0.33, random_state=1)\n",
    "\n",
    "blender = fit_ensemble(models, X_train, X_val, y_train, y_val)\n",
    "yhat = predict_ensemble(models, blender, X_test)\n",
    "\n",
    "l_scores = l_baseline_scores\n",
    "\n",
    "l_scores.append([\n",
    "        'Hard Voting Blender',\n",
    "        yhat,\n",
    "        roc_auc_score(y_test, yhat),\n",
    "        f1_score(y_test, yhat),\n",
    "        precision_score(y_test, yhat),\n",
    "        recall_score(y_test, yhat),\n",
    "        accuracy_score(y_test, yhat)\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "8d0f6c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "blender = fit_ensemble(models, X_train, X_val, y_train, y_val, False)\n",
    "yhat = predict_ensemble(models, blender, X_test, False)\n",
    "\n",
    "l_scores.append([\n",
    "        'Soft Voting Blender',\n",
    "        yhat,\n",
    "        roc_auc_score(y_test, yhat),\n",
    "        f1_score(y_test, yhat),\n",
    "        precision_score(y_test, yhat),\n",
    "        recall_score(y_test, yhat),\n",
    "        accuracy_score(y_test, yhat)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "8e864746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.503030303030303, 0.5959595959595959, 0.5555555555555556, 0.5696969696969697, 0.591919191919192]\n"
     ]
    }
   ],
   "source": [
    "accuracies = evaluate_models(models, X_train, X_val, y_train, y_val)\n",
    "print(accuracies)\n",
    "ensemble = VotingClassifier(estimators=list(zip(model_names, models)), voting='soft', weights=accuracies)\n",
    "ensemble.fit(X_train, y_train)\n",
    "yhat = ensemble.predict(X_test)\n",
    "\n",
    "l_scores.append([\n",
    "        'Soft Weighted Ensemble',\n",
    "        yhat,\n",
    "        roc_auc_score(y_test, yhat),\n",
    "        f1_score(y_test, yhat),\n",
    "        precision_score(y_test, yhat),\n",
    "        recall_score(y_test, yhat),\n",
    "        accuracy_score(y_test, yhat)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "a6170be3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Predictions</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>[1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, ...</td>\n",
       "      <td>0.552486</td>\n",
       "      <td>0.537005</td>\n",
       "      <td>0.513158</td>\n",
       "      <td>0.563177</td>\n",
       "      <td>0.551667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>[0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...</td>\n",
       "      <td>0.578579</td>\n",
       "      <td>0.491736</td>\n",
       "      <td>0.574879</td>\n",
       "      <td>0.429603</td>\n",
       "      <td>0.590000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stocasthic Gradient Descent</td>\n",
       "      <td>[1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, ...</td>\n",
       "      <td>0.554548</td>\n",
       "      <td>0.541096</td>\n",
       "      <td>0.514658</td>\n",
       "      <td>0.570397</td>\n",
       "      <td>0.553333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>[0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, ...</td>\n",
       "      <td>0.564630</td>\n",
       "      <td>0.515038</td>\n",
       "      <td>0.537255</td>\n",
       "      <td>0.494585</td>\n",
       "      <td>0.570000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0.573711</td>\n",
       "      <td>0.402948</td>\n",
       "      <td>0.630769</td>\n",
       "      <td>0.296029</td>\n",
       "      <td>0.595000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Hard Voting Blender</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0.543951</td>\n",
       "      <td>0.363996</td>\n",
       "      <td>0.547619</td>\n",
       "      <td>0.272593</td>\n",
       "      <td>0.570761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Soft Voting Blender</td>\n",
       "      <td>[0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, ...</td>\n",
       "      <td>0.545735</td>\n",
       "      <td>0.426690</td>\n",
       "      <td>0.523707</td>\n",
       "      <td>0.360000</td>\n",
       "      <td>0.564085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Soft Weighted Ensemble</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, ...</td>\n",
       "      <td>0.547226</td>\n",
       "      <td>0.457096</td>\n",
       "      <td>0.515829</td>\n",
       "      <td>0.410370</td>\n",
       "      <td>0.560748</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Model  \\\n",
       "0                Decision Tree   \n",
       "1          Logistic Regression   \n",
       "2  Stocasthic Gradient Descent   \n",
       "3                        Ridge   \n",
       "4                  Naive Bayes   \n",
       "5          Hard Voting Blender   \n",
       "6          Soft Voting Blender   \n",
       "7       Soft Weighted Ensemble   \n",
       "\n",
       "                                         Predictions   ROC AUC  F1-Score  \\\n",
       "0  [1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, ...  0.552486  0.537005   \n",
       "1  [0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...  0.578579  0.491736   \n",
       "2  [1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, ...  0.554548  0.541096   \n",
       "3  [0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, ...  0.564630  0.515038   \n",
       "4  [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  0.573711  0.402948   \n",
       "5  [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  0.543951  0.363996   \n",
       "6  [0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, ...  0.545735  0.426690   \n",
       "7  [0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, ...  0.547226  0.457096   \n",
       "\n",
       "   Precision    Recall  Accuracy  \n",
       "0   0.513158  0.563177  0.551667  \n",
       "1   0.574879  0.429603  0.590000  \n",
       "2   0.514658  0.570397  0.553333  \n",
       "3   0.537255  0.494585  0.570000  \n",
       "4   0.630769  0.296029  0.595000  \n",
       "5   0.547619  0.272593  0.570761  \n",
       "6   0.523707  0.360000  0.564085  \n",
       "7   0.515829  0.410370  0.560748  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_scores_df = pd.DataFrame(l_scores, columns= ['Model', 'Predictions', 'ROC AUC', 'F1-Score', 'Precision', 'Recall', 'Accuracy'])\n",
    "\n",
    "\n",
    "l_scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "2e4d4c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset into train and test sets\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "# split training set into train and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=0.33, random_state=1)\n",
    "\n",
    "blender = fit_ensemble(models, X_train, X_val, y_train, y_val)\n",
    "yhat = predict_ensemble(models, blender, X_test)\n",
    "\n",
    "scores.append([\n",
    "        'Hard Voting Blender',\n",
    "        yhat,\n",
    "        roc_auc_score(y_test, yhat),\n",
    "        f1_score(y_test, yhat),\n",
    "        precision_score(y_test, yhat),\n",
    "        recall_score(y_test, yhat),\n",
    "        accuracy_score(y_test, yhat)\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "6ba73e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "blender = fit_ensemble(models, X_train, X_val, y_train, y_val, False)\n",
    "yhat = predict_ensemble(models, blender, X_test, False)\n",
    "\n",
    "scores.append([\n",
    "        'Soft Voting Blender',\n",
    "        yhat,\n",
    "        roc_auc_score(y_test, yhat),\n",
    "        f1_score(y_test, yhat),\n",
    "        precision_score(y_test, yhat),\n",
    "        recall_score(y_test, yhat),\n",
    "        accuracy_score(y_test, yhat)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "7570a6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = evaluate_models(models, X_train, X_val, y_train, y_val)\n",
    "ensemble = VotingClassifier(estimators=list(zip(model_names, models)), voting='soft', weights=accuracies)\n",
    "ensemble.fit(X_train, y_train)\n",
    "yhat = ensemble.predict(X_test)\n",
    "\n",
    "scores_bck = scores.copy()\n",
    "scores.append([\n",
    "        'Soft Weighted Ensemble',\n",
    "        yhat,\n",
    "        roc_auc_score(y_test, yhat),\n",
    "        f1_score(y_test, yhat),\n",
    "        precision_score(y_test, yhat),\n",
    "        recall_score(y_test, yhat),\n",
    "        accuracy_score(y_test, yhat)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "b47d0f26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Predictions</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, ...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, ...</td>\n",
       "      <td>0.976621</td>\n",
       "      <td>0.976351</td>\n",
       "      <td>0.982993</td>\n",
       "      <td>0.969799</td>\n",
       "      <td>0.976667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stocasthic Gradient Descent</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, ...</td>\n",
       "      <td>0.981677</td>\n",
       "      <td>0.981575</td>\n",
       "      <td>0.979933</td>\n",
       "      <td>0.983221</td>\n",
       "      <td>0.981667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, ...</td>\n",
       "      <td>0.988299</td>\n",
       "      <td>0.988196</td>\n",
       "      <td>0.993220</td>\n",
       "      <td>0.983221</td>\n",
       "      <td>0.988333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, ...</td>\n",
       "      <td>0.954831</td>\n",
       "      <td>0.953528</td>\n",
       "      <td>0.978799</td>\n",
       "      <td>0.929530</td>\n",
       "      <td>0.955000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Hard Voting Blender</td>\n",
       "      <td>[0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, ...</td>\n",
       "      <td>0.991623</td>\n",
       "      <td>0.991870</td>\n",
       "      <td>0.990260</td>\n",
       "      <td>0.993485</td>\n",
       "      <td>0.991667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Soft Voting Blender</td>\n",
       "      <td>[0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, ...</td>\n",
       "      <td>0.991701</td>\n",
       "      <td>0.991843</td>\n",
       "      <td>0.993464</td>\n",
       "      <td>0.990228</td>\n",
       "      <td>0.991667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Soft Weighted Ensemble</td>\n",
       "      <td>[0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, ...</td>\n",
       "      <td>0.986815</td>\n",
       "      <td>0.986885</td>\n",
       "      <td>0.993399</td>\n",
       "      <td>0.980456</td>\n",
       "      <td>0.986667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Model  \\\n",
       "0                Decision Tree   \n",
       "1          Logistic Regression   \n",
       "2  Stocasthic Gradient Descent   \n",
       "3                        Ridge   \n",
       "4                  Naive Bayes   \n",
       "5          Hard Voting Blender   \n",
       "6          Soft Voting Blender   \n",
       "7       Soft Weighted Ensemble   \n",
       "\n",
       "                                         Predictions   ROC AUC  F1-Score  \\\n",
       "0  [0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, ...  1.000000  1.000000   \n",
       "1  [0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, ...  0.976621  0.976351   \n",
       "2  [0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, ...  0.981677  0.981575   \n",
       "3  [0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, ...  0.988299  0.988196   \n",
       "4  [0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, ...  0.954831  0.953528   \n",
       "5  [0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, ...  0.991623  0.991870   \n",
       "6  [0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, ...  0.991701  0.991843   \n",
       "7  [0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, ...  0.986815  0.986885   \n",
       "\n",
       "   Precision    Recall  Accuracy  \n",
       "0   1.000000  1.000000  1.000000  \n",
       "1   0.982993  0.969799  0.976667  \n",
       "2   0.979933  0.983221  0.981667  \n",
       "3   0.993220  0.983221  0.988333  \n",
       "4   0.978799  0.929530  0.955000  \n",
       "5   0.990260  0.993485  0.991667  \n",
       "6   0.993464  0.990228  0.991667  \n",
       "7   0.993399  0.980456  0.986667  "
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df = pd.DataFrame(scores, columns= ['Model', 'Predictions', 'ROC AUC', 'F1-Score', 'Precision', 'Recall', 'Accuracy'])\n",
    "\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "22b42088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset into train and test sets\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(t_X, t_y, test_size=0.2, random_state=1)\n",
    "# split training set into train and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=0.33, random_state=1)\n",
    "\n",
    "blender = fit_ensemble(models, X_train, X_val, y_train, y_val)\n",
    "yhat = predict_ensemble(models, blender, X_test)\n",
    "\n",
    "t_scores.append([\n",
    "        'Hard Voting Blender',\n",
    "        yhat,\n",
    "        roc_auc_score(y_test, yhat),\n",
    "        f1_score(y_test, yhat),\n",
    "        precision_score(y_test, yhat),\n",
    "        recall_score(y_test, yhat),\n",
    "        accuracy_score(y_test, yhat)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "7da1ae58",
   "metadata": {},
   "outputs": [],
   "source": [
    "blender = fit_ensemble(models, X_train, X_val, y_train, y_val, False)\n",
    "yhat = predict_ensemble(models, blender, X_test, False)\n",
    "\n",
    "t_scores.append([\n",
    "        'Soft Voting Blender',\n",
    "        yhat,\n",
    "        roc_auc_score(y_test, yhat),\n",
    "        f1_score(y_test, yhat),\n",
    "        precision_score(y_test, yhat),\n",
    "        recall_score(y_test, yhat),\n",
    "        accuracy_score(y_test, yhat)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "e5462cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = evaluate_models(models, X_train, X_val, y_train, y_val)\n",
    "ensemble = VotingClassifier(estimators=list(zip(model_names, models)), voting='soft', weights=accuracies)\n",
    "ensemble.fit(X_train, y_train)\n",
    "yhat = ensemble.predict(X_test)\n",
    "\n",
    "t_scores.append([\n",
    "        'Soft Weighted Ensemble',\n",
    "        yhat,\n",
    "        roc_auc_score(y_test, yhat),\n",
    "        f1_score(y_test, yhat),\n",
    "        precision_score(y_test, yhat),\n",
    "        recall_score(y_test, yhat),\n",
    "        accuracy_score(y_test, yhat)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "daefe6a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Predictions</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>[0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, ...</td>\n",
       "      <td>0.772792</td>\n",
       "      <td>0.758135</td>\n",
       "      <td>0.724370</td>\n",
       "      <td>0.795203</td>\n",
       "      <td>0.770642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, ...</td>\n",
       "      <td>0.784553</td>\n",
       "      <td>0.765297</td>\n",
       "      <td>0.757685</td>\n",
       "      <td>0.773063</td>\n",
       "      <td>0.785655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stocasthic Gradient Descent</td>\n",
       "      <td>[0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>0.765551</td>\n",
       "      <td>0.753873</td>\n",
       "      <td>0.706452</td>\n",
       "      <td>0.808118</td>\n",
       "      <td>0.761468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, ...</td>\n",
       "      <td>0.778695</td>\n",
       "      <td>0.757604</td>\n",
       "      <td>0.756906</td>\n",
       "      <td>0.758303</td>\n",
       "      <td>0.780651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, ...</td>\n",
       "      <td>0.747051</td>\n",
       "      <td>0.704569</td>\n",
       "      <td>0.783296</td>\n",
       "      <td>0.640221</td>\n",
       "      <td>0.757298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Hard Voting Blender</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, ...</td>\n",
       "      <td>0.778331</td>\n",
       "      <td>0.754468</td>\n",
       "      <td>0.803607</td>\n",
       "      <td>0.710993</td>\n",
       "      <td>0.782319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Soft Weighted Ensemble</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, ...</td>\n",
       "      <td>0.769378</td>\n",
       "      <td>0.748387</td>\n",
       "      <td>0.779271</td>\n",
       "      <td>0.719858</td>\n",
       "      <td>0.772310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Soft Voting Blender</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, ...</td>\n",
       "      <td>0.771944</td>\n",
       "      <td>0.754306</td>\n",
       "      <td>0.771800</td>\n",
       "      <td>0.737589</td>\n",
       "      <td>0.773978</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Model  \\\n",
       "0                Decision Tree   \n",
       "1          Logistic Regression   \n",
       "2  Stocasthic Gradient Descent   \n",
       "3                        Ridge   \n",
       "4                  Naive Bayes   \n",
       "5          Hard Voting Blender   \n",
       "6       Soft Weighted Ensemble   \n",
       "7          Soft Voting Blender   \n",
       "\n",
       "                                         Predictions   ROC AUC  F1-Score  \\\n",
       "0  [0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, ...  0.772792  0.758135   \n",
       "1  [0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, ...  0.784553  0.765297   \n",
       "2  [0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, ...  0.765551  0.753873   \n",
       "3  [0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, ...  0.778695  0.757604   \n",
       "4  [0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, ...  0.747051  0.704569   \n",
       "5  [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, ...  0.778331  0.754468   \n",
       "6  [0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, ...  0.769378  0.748387   \n",
       "7  [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, ...  0.771944  0.754306   \n",
       "\n",
       "   Precision    Recall  Accuracy  \n",
       "0   0.724370  0.795203  0.770642  \n",
       "1   0.757685  0.773063  0.785655  \n",
       "2   0.706452  0.808118  0.761468  \n",
       "3   0.756906  0.758303  0.780651  \n",
       "4   0.783296  0.640221  0.757298  \n",
       "5   0.803607  0.710993  0.782319  \n",
       "6   0.779271  0.719858  0.772310  \n",
       "7   0.771800  0.737589  0.773978  "
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_scores_df = pd.DataFrame(t_scores, columns= ['Model', 'Predictions', 'ROC AUC', 'F1-Score', 'Precision', 'Recall', 'Accuracy'])\n",
    "\n",
    "t_scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017fa10b",
   "metadata": {},
   "source": [
    "3. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4801055",
   "metadata": {},
   "source": [
    "3.1 Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4774fea",
   "metadata": {},
   "source": [
    "3.2 Summary and conclusions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
