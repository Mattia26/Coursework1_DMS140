{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a4b7af7",
   "metadata": {},
   "source": [
    "1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d509d1d0",
   "metadata": {},
   "source": [
    "1.1 Domain-specific Area"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4002196c",
   "metadata": {},
   "source": [
    "1.2 Description of the selected dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8160dcdd",
   "metadata": {},
   "source": [
    "1.3 Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dda711f",
   "metadata": {},
   "source": [
    "1.4 Evaluation Methodology"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9318d0",
   "metadata": {},
   "source": [
    "2. Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48515c2d",
   "metadata": {},
   "source": [
    "2.1 Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43d7acea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/mmenna/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import string\n",
    "import random\n",
    "import numpy as np\n",
    "from numpy import hstack\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk import ngrams\n",
    "from functools import reduce\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.extmath import softmax\n",
    "\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "\n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec98e831",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_processing(text, n = 1):\n",
    "    \"\"\"\n",
    "    Takes in a string of text, then performs the following:\n",
    "    1. Convert text to lower case and remove all punctuation\n",
    "    2. Optionally apply stemming\n",
    "    3. Apply Ngram Tokenisation\n",
    "    4. Returns the tokenised text as a list \n",
    "    \"\"\"\n",
    "    \n",
    "    stemmer = SnowballStemmer(\"english\")\n",
    "    stop = stopwords.words('english')\n",
    "    #write steps here\n",
    "    # lower function\n",
    "    t_1 = lambda x : x.lower()\n",
    "    # Remove punctuation function\n",
    "    t_2 = lambda x : x.translate(str.maketrans('', '', string.punctuation))\n",
    "    # Remove stopwords\n",
    "    t_3 = lambda x : \" \".join([w for w in x.split() if w not in stop])\n",
    "    # Snowball stemming\n",
    "    t_4 = lambda x : \" \".join([stemmer.stem(w) for w in x.split()])\n",
    "    # Ngrams with n number of grams\n",
    "    t_5 = lambda x : [\" \".join(ng) for ng in list(ngrams(x.split(), n))]\n",
    "    \n",
    "    \n",
    "    #List of transformation functions\n",
    "    t = [t_1, t_2, t_3, t_4, t_5]\n",
    "    \n",
    "    #Apply transformations\n",
    "    tokenised = reduce(lambda r, f: f(r), t, text)\n",
    "    \n",
    "    return tokenised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d501f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_1 = sum(1 for line in open('True.csv')) - 1\n",
    "n_2 = sum(1 for line in open('Fake.csv')) - 1\n",
    "s = 1500 #desired sample size\n",
    "skip_1 = sorted(random.sample(range(1,n_1+1),n_1-s)) #the 0-indexed header will not be included in the skip list\n",
    "skip_2 = sorted(random.sample(range(1,n_2+1),n_2-s)) #the 0-indexed header will not be included in the skip list\n",
    "\n",
    "raw_data_true = pd.read_csv('True.csv', skiprows=skip_1)\n",
    "raw_data_fake = pd.read_csv('Fake.csv', skiprows=skip_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7dd86a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_true['isFake'] = 0\n",
    "raw_data_fake['isFake'] = 1\n",
    "raw_data = raw_data_true.append(raw_data_fake)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09af5775",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_t1 = pd.DataFrame()\n",
    "data_t1['article'] = raw_data['title'] + ' ' + raw_data['text']\n",
    "data_t1['isFake'] = raw_data['isFake']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1893ab8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [top, democrat, say, trump, fire, mueller, cou...\n",
       "1       [white, hous, expect, congress, waiv, spend, c...\n",
       "2       [trump, strategi, document, say, russia, meddl...\n",
       "3       [factbox, trump, twitter, decemb, 15, quantico...\n",
       "4       [us, judg, lift, hous, arrest, former, trump, ...\n",
       "                              ...                        \n",
       "1493    [us, delta, forc, begin, target, isi, iraq, th...\n",
       "1494    [final, control, tpp, ttip, tisa, global, corp...\n",
       "1495    [ron, paul, burn, oregon, standoff, juri, null...\n",
       "1496    [seven, iranian, freed, prison, swap, return, ...\n",
       "1497    [blow, 700, million, al, jazeera, america, fin...\n",
       "Name: article, Length: 2998, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag = data_t1['article'].apply(text_processing, n=1)\n",
    "bag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28fb4b23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count Vectorizing...\n",
      "Transforming to tfidf matrix...\n"
     ]
    }
   ],
   "source": [
    "identity = lambda x : x\n",
    "corpus = bag.values\n",
    "print('Count Vectorizing...')\n",
    "vectorizer = CountVectorizer(tokenizer = identity, preprocessor = identity)\n",
    "count_vector = vectorizer.fit_transform(corpus).toarray()\n",
    "print('Transforming to tfidf matrix...')\n",
    "tfidfTransformer = TfidfTransformer()\n",
    "text_tfidf = tfidfTransformer.fit_transform(count_vector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff024d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(text_tfidf.toarray())\n",
    "y = data_t1['isFake']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "756f1eed",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-a5cf4aeba0ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "X_train.reset_index(inplace=True, drop=True)\n",
    "X_test.reset_index(inplace=True, drop=True)\n",
    "y_train.reset_index(inplace=True, drop=True)\n",
    "y_test.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e604ac97",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_raw_data = pd.read_csv('liar_dataset/train.tsv', sep='\\t', names= ['ID','Label','Statement', 'Subject', 'Speaker', 'Speaker Job', 'State', 'Party Aff', 'Credit', 'True', 'Half true', 'Mostly true', 'Pants on fire', 'Context'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "48635d88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>isFake</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Says the Annies List political group supports ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When did the decline of coal start? It started...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hillary Clinton agrees with John McCain \"by vo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Health care reform legislation is likely to ma...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The economic turnaround started at the end of ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10235</th>\n",
       "      <td>There are a larger number of shark attacks in ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10236</th>\n",
       "      <td>Democrats have now become the party of the [At...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10237</th>\n",
       "      <td>Says an alternative to Social Security that op...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10238</th>\n",
       "      <td>On lifting the U.S. Cuban embargo and allowing...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10239</th>\n",
       "      <td>The Department of Veterans Affairs has a manua...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10240 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 article  isFake\n",
       "0      Says the Annies List political group supports ...       1\n",
       "1      When did the decline of coal start? It started...       1\n",
       "2      Hillary Clinton agrees with John McCain \"by vo...       0\n",
       "3      Health care reform legislation is likely to ma...       1\n",
       "4      The economic turnaround started at the end of ...       1\n",
       "...                                                  ...     ...\n",
       "10235  There are a larger number of shark attacks in ...       0\n",
       "10236  Democrats have now become the party of the [At...       0\n",
       "10237  Says an alternative to Social Security that op...       1\n",
       "10238  On lifting the U.S. Cuban embargo and allowing...       1\n",
       "10239  The Department of Veterans Affairs has a manua...       1\n",
       "\n",
       "[10240 rows x 2 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "liar_mapper = {\n",
    "    'false': 1,\n",
    "    'half-true': 1,\n",
    "    'mostly-true': 0,\n",
    "    'true': 0,\n",
    "    'barely-true': 1,\n",
    "    'pants-fire': 1\n",
    "}\n",
    "reduce_fake = lambda x : liar_mapper[x]\n",
    "l_data_t1 = pd.DataFrame()\n",
    "l_data_t1['article'] = l_raw_data['Statement']\n",
    "l_data_t1['isFake'] = l_raw_data['Label'].apply(reduce_fake)\n",
    "\n",
    "l_data_t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9504e829",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [say, anni, list, polit, group, support, third...\n",
       "1        [declin, coal, start, start, natur, gas, took,...\n",
       "2        [hillari, clinton, agre, john, mccain, vote, g...\n",
       "3        [health, care, reform, legisl, like, mandat, f...\n",
       "4                   [econom, turnaround, start, end, term]\n",
       "                               ...                        \n",
       "10235    [larger, number, shark, attack, florida, case,...\n",
       "10236    [democrat, becom, parti, atlanta, metro, area,...\n",
       "10237    [say, altern, social, secur, oper, galveston, ...\n",
       "10238      [lift, us, cuban, embargo, allow, travel, cuba]\n",
       "10239    [depart, veteran, affair, manual, tell, vetera...\n",
       "Name: article, Length: 10240, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag = l_data_t1['article'].apply(text_processing, n=1)\n",
    "bag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b4e31b64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count Vectorizing...\n",
      "Transforming to tfidf matrix...\n"
     ]
    }
   ],
   "source": [
    "corpus = bag.values\n",
    "print('Count Vectorizing...')\n",
    "vectorizer = CountVectorizer(tokenizer = identity, preprocessor = identity)\n",
    "count_vector = vectorizer.fit_transform(corpus).toarray()\n",
    "print('Transforming to tfidf matrix...')\n",
    "tfidfTransformer = TfidfTransformer()\n",
    "text_tfidf = tfidfTransformer.fit_transform(count_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ee492488",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_X = pd.DataFrame(text_tfidf.toarray())\n",
    "l_y = l_data_t1['isFake']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcceb5cf",
   "metadata": {},
   "source": [
    "2.2 Baseline performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b19bfa26",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RidgeClassifierWithProba(RidgeClassifier):\n",
    "    def predict_proba(self, X):\n",
    "        d = self.decision_function(X)\n",
    "        d_2d = np.c_[-d, d]\n",
    "        \n",
    "        return softmax(d_2d)\n",
    "    \n",
    "models= [LinearDiscriminantAnalysis(), \n",
    "         LogisticRegression(random_state=42), \n",
    "         SGDClassifier(max_iter=1000, tol=1e-3, loss='modified_huber'),\n",
    "         RidgeClassifierWithProba()\n",
    "         #SVC(probability=True)\n",
    "        ]\n",
    "model_names = [\n",
    "    \"Linear Discriminant Analysis\",\n",
    "    \"Logistic Regression\",\n",
    "    \"Stocasthic Gradient Descent\",\n",
    "    \"Ridge\"\n",
    "    #\"SVC\"\n",
    "]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "l_X_train, l_X_test, l_y_train, l_y_test = train_test_split(l_X, l_y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dedba8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c84992f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting model  Linear Discriminant Analysis  for Fake News dataset...\n",
      "Fitting model  Linear Discriminant Analysis  for Liar dataset...\n",
      "Fitting model  Logistic Regression  for Fake News dataset...\n",
      "Fitting model  Logistic Regression  for Liar dataset...\n",
      "Fitting model  Stocasthic Gradient Descent  for Fake News dataset...\n",
      "Fitting model  Stocasthic Gradient Descent  for Liar dataset...\n",
      "Fitting model  Ridge  for Fake News dataset...\n",
      "Fitting model  Ridge  for Liar dataset...\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "l_scores = []\n",
    "for i,model in enumerate(models):\n",
    "    print('Fitting model ', model_names[i], 'for Fake News dataset...')\n",
    "    model.fit(X_train, y_train)\n",
    "    yhat = model.predict(X_test)\n",
    "    scores.append([\n",
    "        model_names[i],\n",
    "        yhat,\n",
    "        roc_auc_score(y_test, yhat),\n",
    "        f1_score(y_test, yhat),\n",
    "        precision_score(y_test, yhat),\n",
    "        recall_score(y_test, yhat),\n",
    "        accuracy_score(y_test, yhat)\n",
    "    ])\n",
    "    print('Fitting model ', model_names[i], 'for Liar dataset...')\n",
    "    model.fit(l_X_train, l_y_train)\n",
    "    yhat = model.predict(l_X_test)\n",
    "    l_scores.append([\n",
    "        model_names[i],\n",
    "        yhat,\n",
    "        roc_auc_score(l_y_test, yhat),\n",
    "        f1_score(l_y_test, yhat),\n",
    "        precision_score(l_y_test, yhat),\n",
    "        recall_score(l_y_test, yhat),\n",
    "        accuracy_score(l_y_test, yhat)\n",
    "    ])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cfa1632e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Predictions</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Discriminant Analysis</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, ...</td>\n",
       "      <td>0.896742</td>\n",
       "      <td>0.891608</td>\n",
       "      <td>0.940959</td>\n",
       "      <td>0.847176</td>\n",
       "      <td>0.896494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, ...</td>\n",
       "      <td>0.961660</td>\n",
       "      <td>0.961345</td>\n",
       "      <td>0.972789</td>\n",
       "      <td>0.950166</td>\n",
       "      <td>0.961603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stocasthic Gradient Descent</td>\n",
       "      <td>[0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, ...</td>\n",
       "      <td>0.976627</td>\n",
       "      <td>0.976744</td>\n",
       "      <td>0.976744</td>\n",
       "      <td>0.976744</td>\n",
       "      <td>0.976628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, ...</td>\n",
       "      <td>0.983305</td>\n",
       "      <td>0.983389</td>\n",
       "      <td>0.983389</td>\n",
       "      <td>0.983389</td>\n",
       "      <td>0.983306</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Model  \\\n",
       "0  Linear Discriminant Analysis   \n",
       "1           Logistic Regression   \n",
       "2   Stocasthic Gradient Descent   \n",
       "3                         Ridge   \n",
       "\n",
       "                                         Predictions   ROC AUC  F1-Score  \\\n",
       "0  [0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, ...  0.896742  0.891608   \n",
       "1  [0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, ...  0.961660  0.961345   \n",
       "2  [0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, ...  0.976627  0.976744   \n",
       "3  [0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, ...  0.983305  0.983389   \n",
       "\n",
       "   Precision    Recall  Accuracy  \n",
       "0   0.940959  0.847176  0.896494  \n",
       "1   0.972789  0.950166  0.961603  \n",
       "2   0.976744  0.976744  0.976628  \n",
       "3   0.983389  0.983389  0.983306  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df = pd.DataFrame(scores, columns= ['Model', 'Predictions', 'ROC AUC', 'F1-Score', 'Precision', 'Recall', 'Accuracy'])\n",
    "\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0d6dff",
   "metadata": {},
   "source": [
    "2.3 Classification Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d981a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the blending ensemble\n",
    "def fit_ensemble(models, X_train, X_val, y_train, y_val, hard=True):\n",
    "    # fit all models on the training set and predict on hold out set\n",
    "    meta_X = list()\n",
    "    for model in models:\n",
    "        # fit in training set\n",
    "        model.fit(X_train, y_train)\n",
    "        # predict on hold out set\n",
    "        yhat = model.predict(X_val) if hard else model.predict_proba(X_val)\n",
    "        # reshape predictions into a matrix with one column\n",
    "        if hard:\n",
    "            yhat = yhat.reshape(len(yhat), 1)\n",
    "        # store predictions as input for blending\n",
    "        meta_X.append(yhat)\n",
    "    # create 2d array from predictions, each set is an input feature\n",
    "    meta_X = hstack(meta_X)\n",
    "    # define blending model\n",
    "    blender = LogisticRegression()\n",
    "    # fit on predictions from base models\n",
    "    blender.fit(meta_X, y_val)\n",
    "    return blender\n",
    "\n",
    "# make a prediction with the blending ensemble\n",
    "def predict_ensemble(models, blender, X_test, hard=True):\n",
    "    # make predictions with base models\n",
    "    meta_X = list()\n",
    "    for model in models:\n",
    "        # predict with base model\n",
    "        yhat = model.predict(X_test) if hard else model.predict_proba(X_test)\n",
    "        # reshape predictions into a matrix with one column\n",
    "        if hard: \n",
    "            yhat = yhat.reshape(len(yhat), 1)\n",
    "        # store prediction\n",
    "        meta_X.append(yhat)\n",
    "    # create 2d array from predictions, each set is an input feature\n",
    "    meta_X = hstack(meta_X)\n",
    "    # predict\n",
    "    return blender.predict(meta_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2e4d4c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset into train and test sets\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, test_size=0.5, random_state=1)\n",
    "# split training set into train and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=0.33, random_state=1)\n",
    "\n",
    "blender = fit_ensemble(models, X_train, X_val, y_train, y_val)\n",
    "yhat = predict_ensemble(models, blender, X_test)\n",
    "\n",
    "scores.append([\n",
    "        'Hard Voting Blender',\n",
    "        yhat,\n",
    "        roc_auc_score(y_test, yhat),\n",
    "        f1_score(y_test, yhat),\n",
    "        precision_score(y_test, yhat),\n",
    "        recall_score(y_test, yhat),\n",
    "        accuracy_score(y_test, yhat)\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6ba73e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "blender = fit_ensemble(models, X_train, X_val, y_train, y_val, False)\n",
    "yhat = predict_ensemble(models, blender, X_test, False)\n",
    "\n",
    "scores.append([\n",
    "        'Soft Voting Blender',\n",
    "        yhat,\n",
    "        roc_auc_score(y_test, yhat),\n",
    "        f1_score(y_test, yhat),\n",
    "        precision_score(y_test, yhat),\n",
    "        recall_score(y_test, yhat),\n",
    "        accuracy_score(y_test, yhat)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d9057c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate each base model\n",
    "def evaluate_models(models, X_train, X_val, y_train, y_val):\n",
    "    # fit and evaluate the models\n",
    "    scores = list()\n",
    "    for model in models:\n",
    "        # fit the model\n",
    "        model.fit(X_train, y_train)\n",
    "        # evaluate the model\n",
    "        yhat = model.predict(X_val)\n",
    "        acc = accuracy_score(y_val, yhat)\n",
    "        # store the performance\n",
    "        scores.append(acc)\n",
    "    # report model performance\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7570a6f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8, 0.9636363636363636, 0.9575757575757575, 0.9797979797979798]\n"
     ]
    }
   ],
   "source": [
    "accuracies = evaluate_models(models, X_train, X_val, y_train, y_val)\n",
    "print(accuracies)\n",
    "ensemble = VotingClassifier(estimators=list(zip(model_names, models)), voting='soft', weights=accuracies)\n",
    "ensemble.fit(X_train, y_train)\n",
    "yhat = ensemble.predict(X_test)\n",
    "\n",
    "scores_bck = scores.copy()\n",
    "scores.append([\n",
    "        'Soft Weighted Ensemble',\n",
    "        yhat,\n",
    "        roc_auc_score(y_test, yhat),\n",
    "        f1_score(y_test, yhat),\n",
    "        precision_score(y_test, yhat),\n",
    "        recall_score(y_test, yhat),\n",
    "        accuracy_score(y_test, yhat)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b47d0f26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Predictions</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Discriminant Analysis</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, ...</td>\n",
       "      <td>0.896742</td>\n",
       "      <td>0.891608</td>\n",
       "      <td>0.940959</td>\n",
       "      <td>0.847176</td>\n",
       "      <td>0.896494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, ...</td>\n",
       "      <td>0.961660</td>\n",
       "      <td>0.961345</td>\n",
       "      <td>0.972789</td>\n",
       "      <td>0.950166</td>\n",
       "      <td>0.961603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stocasthic Gradient Descent</td>\n",
       "      <td>[0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, ...</td>\n",
       "      <td>0.976627</td>\n",
       "      <td>0.976744</td>\n",
       "      <td>0.976744</td>\n",
       "      <td>0.976744</td>\n",
       "      <td>0.976628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, ...</td>\n",
       "      <td>0.983305</td>\n",
       "      <td>0.983389</td>\n",
       "      <td>0.983389</td>\n",
       "      <td>0.983389</td>\n",
       "      <td>0.983306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hard Voting Blender</td>\n",
       "      <td>[1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0.973907</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.968627</td>\n",
       "      <td>0.980159</td>\n",
       "      <td>0.973965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Soft Voting Blender</td>\n",
       "      <td>[1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0.969277</td>\n",
       "      <td>0.969617</td>\n",
       "      <td>0.968338</td>\n",
       "      <td>0.970899</td>\n",
       "      <td>0.969292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Soft Weighted Ensemble</td>\n",
       "      <td>[1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0.971274</td>\n",
       "      <td>0.971617</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.973545</td>\n",
       "      <td>0.971295</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Model  \\\n",
       "0  Linear Discriminant Analysis   \n",
       "1           Logistic Regression   \n",
       "2   Stocasthic Gradient Descent   \n",
       "3                         Ridge   \n",
       "4           Hard Voting Blender   \n",
       "5           Soft Voting Blender   \n",
       "6        Soft Weighted Ensemble   \n",
       "\n",
       "                                         Predictions   ROC AUC  F1-Score  \\\n",
       "0  [0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, ...  0.896742  0.891608   \n",
       "1  [0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, ...  0.961660  0.961345   \n",
       "2  [0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, ...  0.976627  0.976744   \n",
       "3  [0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, ...  0.983305  0.983389   \n",
       "4  [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  0.973907  0.974359   \n",
       "5  [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  0.969277  0.969617   \n",
       "6  [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  0.971274  0.971617   \n",
       "\n",
       "   Precision    Recall  Accuracy  \n",
       "0   0.940959  0.847176  0.896494  \n",
       "1   0.972789  0.950166  0.961603  \n",
       "2   0.976744  0.976744  0.976628  \n",
       "3   0.983389  0.983389  0.983306  \n",
       "4   0.968627  0.980159  0.973965  \n",
       "5   0.968338  0.970899  0.969292  \n",
       "6   0.969697  0.973545  0.971295  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df = pd.DataFrame(scores, columns= ['Model', 'Predictions', 'ROC AUC', 'F1-Score', 'Precision', 'Recall', 'Accuracy'])\n",
    "\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017fa10b",
   "metadata": {},
   "source": [
    "3. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4801055",
   "metadata": {},
   "source": [
    "3.1 Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4774fea",
   "metadata": {},
   "source": [
    "3.2 Summary and conclusions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
